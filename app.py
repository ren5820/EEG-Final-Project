import streamlit as st
import torch
import torch.nn as nn
import mne
import numpy as np
import os
import matplotlib.pyplot as plt

# 1. å®šä¹‰æ¨¡å‹æ¶æ„
class SimpleEEGNet(nn.Module):
    def __init__(self, num_classes=3, channels=64, samples=320):
        super(SimpleEEGNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, (1, 33), padding=(0, 16))
        self.bn1 = nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16, 32, (channels, 1))
        self.bn2 = nn.BatchNorm2d(32)
        self.pooling = nn.AvgPool2d((1, 4))
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(32 * 1 * 80, num_classes)

    def forward(self, x):
        x = torch.relu(self.bn1(self.conv1(x)))
        x = torch.relu(self.bn2(self.conv2(x)))
        x = self.pooling(x)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        return self.fc(x)

# 2. åŸºç¡€é…ç½®ä¸è·¯å¾„åˆå§‹åŒ–
st.set_page_config(page_title="BCI Medical Terminal", layout="wide")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# 3. ä¾§è¾¹æ ï¼šæˆæƒä¸åŠ¨æ€æ ·æœ¬åŠ è½½
with st.sidebar:
    st.header("ğŸ”’ ç³»ç»Ÿæˆæƒ")
    password = st.text_input("è¾“å…¥è®¿é—®ä»£ç ", type="password")
    if password != "Centria2026":
        st.warning("è¯·è¾“å…¥æˆæƒç è®¿é—®åŒ»ç–—ç»ˆç«¯")
        st.stop()
    
    st.success("æˆæƒæˆåŠŸ")
    st.markdown("---")
    st.subheader("ğŸ’¡ æ¼”ç¤ºæ¨¡å¼")
    
    # è‡ªåŠ¨æ£€ç´¢ data/test_samples æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ .fif æ–‡ä»¶
    sample_dir = os.path.join(BASE_DIR, "data", "test_samples")
    if os.path.exists(sample_dir):
        available_files = [f for f in os.listdir(sample_dir) if f.endswith('.fif')]
        samples = {f: os.path.join(sample_dir, f) for f in sorted(available_files)}
    else:
        samples = {}
        st.error("æœªæ‰¾åˆ° data/test_samples ç›®å½•ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“")

    sample_choice = st.selectbox("é€‰æ‹©å†…ç½®æ ·æœ¬", ["æ— "] + list(samples.keys()))

# 4. æ¨¡å‹åŠ è½½å‡½æ•°
@st.cache_resource
def load_model():
    model = SimpleEEGNet()
    model_path = os.path.join(BASE_DIR, 'results', 'model.pth')
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        return model
    return None

model = load_model()

# 5. ä¸»ç•Œé¢
st.title("ğŸ§  è„‘æœºæ¥å£åŒ»ç–—è¾…åŠ©æ§åˆ¶ç»ˆç«¯")
st.info("å½“å‰ AI è¯†åˆ«å‡†ç¡®ç‡ï¼š82.33% | ä¿¡å·çª—å£ï¼š2.0 ç§’")

uploaded_file = st.file_uploader("ä¸Šä¼ è„‘ç”µä¿¡å· (.fif)", type=["fif"])

data_source = None
if uploaded_file:
    temp_path = os.path.join(BASE_DIR, "temp.fif")
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    data_source = temp_path
elif sample_choice != "æ— ":
    data_source = samples[sample_choice]

if data_source:
    try:
        # æ•°æ®è¯»å–ä¸é¢„å¤„ç†
        epochs = mne.read_epochs(data_source, preload=True, verbose=False)
        epochs.resample(160, verbose=False)
        epochs.filter(8., 30., verbose=False)
        raw_data = epochs.get_data()

        # å¯¹é½æ•°æ®é•¿åº¦ä¸º 320 ä¸ªé‡‡æ ·ç‚¹
        if raw_data.shape[2] < 320:
            raw_data = np.pad(raw_data, ((0, 0), (0, 0), (0, 320 - raw_data.shape[2])))
        else:
            raw_data = raw_data[:, :, :320]

        # Z-score æ ‡å‡†åŒ–ï¼š$z = \frac{x - \mu}{\sigma}$
        norm_data = (raw_data - np.mean(raw_data)) / (np.std(raw_data) + 1e-8)

        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("ğŸ“Š å®æ—¶æ³¢å½¢è¯Šæ–­")
            fig, ax = plt.subplots(figsize=(10, 3))
            ax.plot(norm_data[0, 0, :], color='#00FFAA', linewidth=1)
            ax.set_ylim(-4, 4)
            ax.set_ylabel("æ ‡å‡†åŒ–å¹…å€¼ (Z)")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

        with col2:
            st.subheader("ğŸ•¹ï¸ æŒ‡ä»¤ç¿»è¯‘å™¨")
            if st.button("å¼€å§‹å®æ—¶åˆ†æ", use_container_width=True):
                input_tensor = torch.FloatTensor(norm_data).unsqueeze(1)
                with torch.no_grad():
                    logits = model(input_tensor)
                    probs = torch.nn.functional.softmax(logits, dim=1)
                    conf, pred = torch.max(probs, 1)

                res_idx = pred[0].item()
                res_conf = conf[0].item() * 100
                
                cmds = {
                    0: {"n": "å¾…å‘½/åœæ­¢", "i": "â¸ï¸", "c": "gray"},
                    1: {"n": "å·¦è½¬æŒ‡ä»¤", "i": "â¬…ï¸", "c": "#1E90FF"},
                    2: {"n": "å³è½¬æŒ‡ä»¤", "i": "â¡ï¸", "c": "#32CD32"}
                }
                
                target = cmds[res_idx]
                st.markdown(f"""
                    <div style="background-color: {target['c']}; padding: 25px; border-radius: 15px; text-align: center; color: white;">
                        <h1 style="font-size: 70px; margin: 0;">{target['i']}</h1>
                        <h2 style="margin: 0;">{target['n']}</h2>
                    </div>
                """, unsafe_allow_html=True)
                
                st.progress(res_conf / 100)
                st.write(f"**é¢„æµ‹ç½®ä¿¡åº¦ï¼š** {res_conf:.2f}%")

    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥ï¼š{e}")
